{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPCh98oL9PAxdQxS7xWHVzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maggieliuzzi/deep_learning/blob/master/TensorFlow1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsODl-ujoQcx",
        "colab_type": "text"
      },
      "source": [
        "**TensorFlow 1 Basics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTTllLoOoVhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0059dcc2-6d5e-477a-b30b-c2a4bfb34230"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf  # TensorFlow 1\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qCrDa3Eocz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Placeholders\n",
        "\n",
        "A = tf.placeholder(tf.float32, shape=(5, 5), name='A')  # shape and name are optional\n",
        "v = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wosYP2VcpC_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w = tf.matmul(A, v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rteBf92pogBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "05aef673-52a3-41c9-ab83-c87468a2ca6e"
      },
      "source": [
        "with tf.Session() as session:\n",
        "    # the variable values are fed in via the appropriately named argument \"feed_dict\"\n",
        "    # v needs to be of shape=(5, 1) not just shape=(5,)\n",
        "    output = session.run(w, feed_dict={A: np.random.randn(5, 5), v: np.random.randn(5, 1)})\n",
        "\n",
        "    print(output, type(output))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.4074817 ]\n",
            " [ 1.6627809 ]\n",
            " [ 1.2102717 ]\n",
            " [-0.36671883]\n",
            " [ 4.8174543 ]] <class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YstCPBWorEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TensorFlow variables are like Theano shared variables.\n",
        "# But Theano variables are like TensorFlow placeholders.\n",
        "\n",
        "# A tf variable can be initialized with a numpy array or a tf array, \n",
        "# or anything that can be turned into a tf tensor\n",
        "x = tf.Variable(tf.random_normal((2, 2)))\n",
        "# x = tf.Variable(np.random.randn(2, 2))\n",
        "t = tf.Variable(0) # a scalar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWhEWjRdorOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0f295501-77e1-46d5-f5f7-b14b015b1600"
      },
      "source": [
        "# initialise the variables first\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as session:\n",
        "    out = session.run(init) # then \"run\" the init operation\n",
        "    # print(out) # None\n",
        "\n",
        "    print(x.eval())  # the initial value of x  # eval() in tf is like get_value() in Theano\n",
        "    print(t.eval())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.258659    3.6224153 ]\n",
            " [-0.05675203  0.7406058 ]]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hlvuh_MpcfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# finding minimum of a simple cost function\n",
        "u = tf.Variable(20.0)\n",
        "cost = u*u + u + 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFDnXDKjpcs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unlike Theano, in TensorFlow you don't write the updates yourself, \n",
        "# you choose an optimiser that implements the algorithm you want\n",
        "train_op = tf.train.GradientDescentOptimizer(0.3).minimize(cost)  # learning rate: 0.3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHWgicFhoFhz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aa70ea98-a844-4340-b08e-6183f593e18f"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "    session.run(init)  # running a session\n",
        "\n",
        "    # While the weight update is automated, the loop itself is not, so call train_op until convergence\n",
        "    for i in range(12):\n",
        "        session.run(train_op)\n",
        "        print(\"i = %d, cost = %.3f, u = %.3f\" % (i, cost.eval(), u.eval()))  # tracking the cost function"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i = 0, cost = 67.990, u = 7.700\n",
            "i = 1, cost = 11.508, u = 2.780\n",
            "i = 2, cost = 2.471, u = 0.812\n",
            "i = 3, cost = 1.025, u = 0.025\n",
            "i = 4, cost = 0.794, u = -0.290\n",
            "i = 5, cost = 0.757, u = -0.416\n",
            "i = 6, cost = 0.751, u = -0.466\n",
            "i = 7, cost = 0.750, u = -0.487\n",
            "i = 8, cost = 0.750, u = -0.495\n",
            "i = 9, cost = 0.750, u = -0.498\n",
            "i = 10, cost = 0.750, u = -0.499\n",
            "i = 11, cost = 0.750, u = -0.500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms7pDfEwqvIr",
        "colab_type": "text"
      },
      "source": [
        "**Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPiyyZ75quiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_normalized_data():\n",
        "    print(\"Reading in and transforming data...\")\n",
        "\n",
        "    if not os.path.exists('../large_files/train.csv'):\n",
        "        print('Looking for ../large_files/train.csv')\n",
        "        print('You have not downloaded the data and/or not placed the files in the correct location.')\n",
        "        print('Please get the data from: https://www.kaggle.com/c/digit-recognizer')\n",
        "        print('Place train.csv in the folder large_files adjacent to the class folder')\n",
        "        exit()\n",
        "\n",
        "    df = pd.read_csv('../large_files/train.csv')\n",
        "    data = df.values.astype(np.float32)\n",
        "    np.random.shuffle(data)\n",
        "    X = data[:, 1:]\n",
        "    Y = data[:, 0]\n",
        "\n",
        "    Xtrain = X[:-1000]\n",
        "    Ytrain = Y[:-1000]\n",
        "    Xtest  = X[-1000:]\n",
        "    Ytest  = Y[-1000:]\n",
        "\n",
        "    # normalize the data\n",
        "    mu = Xtrain.mean(axis=0)\n",
        "    std = Xtrain.std(axis=0)\n",
        "    np.place(std, std == 0, 1)\n",
        "    Xtrain = (Xtrain - mu) / std\n",
        "    Xtest = (Xtest - mu) / std\n",
        "    \n",
        "    return Xtrain, Xtest, Ytrain, Ytest\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA9XJ2btq7A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def y2indicator(y):\n",
        "    N = len(y)\n",
        "    y = y.astype(np.int32)\n",
        "    ind = np.zeros((N, 10))\n",
        "    for i in range(N):\n",
        "        ind[i, y[i]] = 1\n",
        "    return ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5fRiAEnrAzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def error_rate(p, t):\n",
        "    return np.mean(p != t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0glyLBCDrBNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# step 1: get the data and define all the usual variables\n",
        "Xtrain, Xtest, Ytrain, Ytest = get_normalized_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHisUJ7Qs_FG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_iter = 15\n",
        "print_period = 50\n",
        "\n",
        "lr = 0.00004\n",
        "reg = 0.01\n",
        "\n",
        "Ytrain_ind = y2indicator(Ytrain)\n",
        "Ytest_ind = y2indicator(Ytest)\n",
        "\n",
        "N, D = Xtrain.shape\n",
        "batch_sz = 500\n",
        "n_batches = N // batch_sz\n",
        "\n",
        "M1 = 300  # size of 1st hidden layer\n",
        "M2 = 100  # size of 2nd hidden layer\n",
        "K = 10\n",
        "W1_init = np.random.randn(D, M1) / np.sqrt(D)\n",
        "b1_init = np.zeros(M1)\n",
        "W2_init = np.random.randn(M1, M2) / np.sqrt(M1)\n",
        "b2_init = np.zeros(M2)\n",
        "W3_init = np.random.randn(M2, K) / np.sqrt(M2)\n",
        "b3_init = np.zeros(K)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idLzojWps_MG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define variables and expressions\n",
        "X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
        "T = tf.placeholder(tf.float32, shape=(None, K), name='T')\n",
        "W1 = tf.Variable(W1_init.astype(np.float32))\n",
        "b1 = tf.Variable(b1_init.astype(np.float32))\n",
        "W2 = tf.Variable(W2_init.astype(np.float32))\n",
        "b2 = tf.Variable(b2_init.astype(np.float32))\n",
        "W3 = tf.Variable(W3_init.astype(np.float32))\n",
        "b3 = tf.Variable(b3_init.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBxxEI6ztTKS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the model\n",
        "Z1 = tf.nn.relu( tf.matmul(X, W1) + b1 )\n",
        "Z2 = tf.nn.relu( tf.matmul(Z1, W2) + b2 )\n",
        "Yish = tf.matmul(Z2, W3) + b3 # the softmax is already included in the cost function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9_M5YDktYP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# softmax_cross_entropy_with_logits take in the \"logits\"\n",
        "# if you wanted to know the actual output of the neural net,\n",
        "# you could pass \"Yish\" into tf.nn.softmax(logits)\n",
        "cost = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=Yish, labels=T))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBtApfF2tTQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we choose the optimizer but don't implement the algorithm ourselves\n",
        "# let's go with RMSprop, since we just learned about it.\n",
        "# it includes momentum!\n",
        "train_op = tf.train.RMSPropOptimizer(lr, decay=0.99, momentum=0.9).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymyOCRRmtcdy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we'll use this to calculate the error rate\n",
        "predict_op = tf.argmax(Yish, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St2hM78Ptdzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "costs = []\n",
        "init = tf.global_variables_initializer()\n",
        "with tf.Session() as session:\n",
        "    session.run(init)\n",
        "\n",
        "    for i in range(max_iter):\n",
        "        for j in range(n_batches):\n",
        "            Xbatch = Xtrain[j*batch_sz:(j*batch_sz + batch_sz),]\n",
        "            Ybatch = Ytrain_ind[j*batch_sz:(j*batch_sz + batch_sz),]\n",
        "\n",
        "            session.run(train_op, feed_dict={X: Xbatch, T: Ybatch})\n",
        "            if j % print_period == 0:\n",
        "                test_cost = session.run(cost, feed_dict={X: Xtest, T: Ytest_ind})\n",
        "                prediction = session.run(predict_op, feed_dict={X: Xtest})\n",
        "                err = error_rate(prediction, Ytest)\n",
        "                print(\"Cost / err at iteration i=%d, j=%d: %.3f / %.3f\" % (i, j, test_cost, err))\n",
        "                costs.append(test_cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhMt4MDrtd5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(costs)\n",
        "plt.show()\n",
        "# increase max_iter and notice how the test cost starts to increase.\n",
        "# are we overfitting by adding that extra layer?\n",
        "# how would you add regularization to this model?"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}